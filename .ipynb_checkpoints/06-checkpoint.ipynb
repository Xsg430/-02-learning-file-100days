{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了配合斯坦福cs224n课程，最近开始看tensorflow文档。\n",
    "今天找了一个博客用tensorflow把逻辑回归又实现了一下\n",
    "博客地址：https://segmentfault.com/a/1190000009954640\n",
    "但是因为anaconda的python是3.7的还无法安装tensorflow，就先用pycharm编译好了再发上来。\n",
    "运行结果我做了比对，降低一个量级后，分类准确率确实有下降\n",
    "~~~python\n",
    "'''\n",
    "使用TensorFlow对逻辑回归进行复现，\n",
    "数据集为coursera ex2data1.txt，通过成绩预测学生是否会被录取\n",
    "'''\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('ex2data1.txt', header=None)\n",
    "train_data = df.values\n",
    "# 前两列为输入X，第三列为输出\n",
    "train_X = train_data[:, :-1]\n",
    "train_y = train_data[:, -1:]\n",
    "feature_num = len(train_X[0])\n",
    "sample_num = len(train_X)\n",
    "# print(\"Size of train_X: {}x{}\".format(sample_num, feature_num))\n",
    "# print(\"Size of train_y: {}x{}\".format(len(train_y), len(train_y[0])))\n",
    "~~~\n",
    "使用 TensorFlow 定义两个变量用来存放我们的训练用数据。placeholder为占位符\n",
    "~~~python\n",
    "# 模型设计\n",
    "X = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "~~~\n",
    "需要训练的参数W和b\n",
    "~~~python\n",
    "W = tf.Variable(tf.zeros([feature_num, 1]))\n",
    "b = tf.Variable([-.9])\n",
    "~~~\n",
    "表达损失函数是分三步进行的：\n",
    "- 先分别将求和内的两部分表示出来，\n",
    "- 再将它们加和并和外面的常数m进行运算，\n",
    "- 最后对这个向量进行求和，便得到了损失函数的值。\n",
    "~~~python\n",
    "db = tf.matmul(X, tf.reshape(W, [-1, 1])) + b\n",
    "hyp = tf.sigmoid(db)\n",
    "cost0 = y * tf.log(hyp)\n",
    "cost1 = (1 - y) * tf.log(1 - hyp)\n",
    "cost = (cost0 + cost1) / -sample_num\n",
    "loss = tf.reduce_sum(cost)\n",
    "~~~\n",
    "定义优化的方法，0.001是学习率\n",
    "~~~python\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.001)\n",
    "train = optimizer.minimize(loss)\n",
    "~~~\n",
    "训练模型\n",
    "定义variable初始化，每运行1000步就输出一次W和b\n",
    "~~~python\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "feed_dict = {X: train_X, y: train_y}\n",
    "for step in range(100000):\n",
    "    sess.run(train, feed_dict)\n",
    "    if step % 1000 == 0:\n",
    "        print(step, sess.run(W).flatten(), sess.run(b).flatten())\n",
    "~~~\n",
    "对运行结果进行可视化处理\n",
    "999900 [0.12887694 0.12310407] [-15.472656]  \n",
    "99900 [0.04858239 0.04162483] [-5.248103]\n",
    "~~~python\n",
    "if __name__ == '__main__':\n",
    "    # logistic_regression(train_X, train_y)\n",
    "\n",
    "    w = [0.04858239, 0.04162483]\n",
    "    b = -5.248103\n",
    "    x1 = train_data[:, 0]\n",
    "    x2 = train_data[:, 1]\n",
    "    y = train_data[:, -1:]\n",
    "    for x1p, x2p, yp in zip(x1, x2, y):\n",
    "        if yp == 0:\n",
    "            plt.scatter(x1p, x2p, marker='x', c='r')\n",
    "        else:\n",
    "            plt.scatter(x1p, x2p, marker='o', c='g')\n",
    "\n",
    "    x = np.linspace(20, 100, 10)\n",
    "    y = []\n",
    "    for i in x:\n",
    "        y.append((i * -w[1] - b) / w[0])\n",
    "\n",
    "    plt.plot(x, y)\n",
    "    plt.show()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "使用TensorFlow对逻辑回归进行复现，\n",
    "数据集为coursera ex2data1.txt，通过成绩预测学生是否会被录取\n",
    "'''\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('ex2data1.txt', header=None)\n",
    "train_data = df.values\n",
    "# 前两列为输入X，第三列为输出\n",
    "train_X = train_data[:, :-1]\n",
    "train_y = train_data[:, -1:]\n",
    "feature_num = len(train_X[0])\n",
    "sample_num = len(train_X)\n",
    "\n",
    "# print(\"Size of train_X: {}x{}\".format(sample_num, feature_num))\n",
    "# print(\"Size of train_y: {}x{}\".format(len(train_y), len(train_y[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression():\n",
    "    global y, b\n",
    "    # 模型设计\n",
    "    # 使用 TensorFlow 定义两个变量用来存放我们的训练用数据。placeholder为占位符\n",
    "    X = tf.placeholder(tf.float32)\n",
    "    y = tf.placeholder(tf.float32)\n",
    "    # 需要训练的参数W和b\n",
    "    W = tf.Variable(tf.zeros([feature_num, 1]))\n",
    "    b = tf.Variable([-.9])\n",
    "    # 使用tensorflow表达损失函数\n",
    "    '''\n",
    "    表达损失函数是分三步进行的：先分别将求和内的两部分表示出来，\n",
    "    再将它们加和并和外面的常数m进行运算，最后对这个向量进行求和，\n",
    "    便得到了损失函数的值。\n",
    "    '''\n",
    "    db = tf.matmul(X, tf.reshape(W, [-1, 1])) + b\n",
    "    hyp = tf.sigmoid(db)\n",
    "    cost0 = y * tf.log(hyp)\n",
    "    cost1 = (1 - y) * tf.log(1 - hyp)\n",
    "    cost = (cost0 + cost1) / -sample_num\n",
    "    loss = tf.reduce_sum(cost)\n",
    "    # 定义优化的方法，0.001是学习率\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.001)\n",
    "    train = optimizer.minimize(loss)\n",
    "    # 训练模型\n",
    "    # 定义variable初始化\n",
    "    '''\n",
    "    gpu分配显存\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "    sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "    '''\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    feed_dict = {X: train_X, y: train_y}\n",
    "    for step in range(100000):\n",
    "        sess.run(train, feed_dict)\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run(W).flatten(), sess.run(b).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    '''\n",
    "    运行结果\n",
    "    999900 [0.12887694 0.12310407] [-15.472656]\n",
    "    99900 [0.04858239 0.04162483] [-5.248103]\n",
    "    '''\n",
    "    # logistic_regression(train_X, train_y)\n",
    "\n",
    "    w = [0.04858239, 0.04162483]\n",
    "    b = -5.248103\n",
    "    x1 = train_data[:, 0]\n",
    "    x2 = train_data[:, 1]\n",
    "    y = train_data[:, -1:]\n",
    "\n",
    "    '''\n",
    "    其中，我们用红色的x代表没有被录取，用绿色的o代表被录取。\n",
    "    其次我们将训练得出的决策边界XW+b=0表示到图表上：\n",
    "    '''\n",
    "\n",
    "    for x1p, x2p, yp in zip(x1, x2, y):\n",
    "        if yp == 0:\n",
    "            plt.scatter(x1p, x2p, marker='x', c='r')\n",
    "        else:\n",
    "            plt.scatter(x1p, x2p, marker='o', c='g')\n",
    "\n",
    "    x = np.linspace(20, 100, 10)\n",
    "    y = []\n",
    "    for i in x:\n",
    "        y.append((i * -w[1] - b) / w[0])\n",
    "\n",
    "    plt.plot(x, y)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
