{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Tensorflow实现逻辑回归\n",
    "讨论如何通过系统中的线性模型预测连续值参数。  \n",
    "如果对象要求在两个选择中抉择呢？  \n",
    "答案简单，我们转换为可以解决一个分类问题。  \n",
    "### 数据集\n",
    "使用MNIST数据集（看来终于要试试这个大名鼎鼎的数据集了，暑假的时候看了一下。）  \n",
    "MNIST数据集包括55000训练集和10000测试集。  \n",
    "图片是28*28，每一张图代表一个手写数字（0-9任意一个）。  \n",
    "我们创建一个大小为764的特征向量，仅使用0和1图。\n",
    "### 逻辑回归\n",
    "在线性回归中，使用线性方程进行预测。另一方面，逻辑回归中我们通过预测一个二元标签0或1。  \n",
    "在逻辑回归中，预测输出是输入样本属于我们的情况下数字“1”的目标类的概率。  \n",
    "损失函数包括两方面，并且在每一个采样中考虑到二进制标记，只有一个是非0的。  \n",
    "## 处理流程\n",
    "- 引入数据集，包含0和1的部分。\n",
    "- 实现逻辑回归。用于逻辑回归的代码很大程度上受到[《训练卷积神经网络作为分类器》](http://www.machinelearninguru.com/deep_learning/tensorflow/neural_networks/cnn_classifier/cnn_classifier.html)的启发。我们参考上述帖子以更好地理解实现细节。  \n",
    "- 教程中，仅仅解释数据处理、实现逻辑回归，其余部分可以参考之前CNN分类器。\n",
    "### 引入库\n",
    "~~~python\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "~~~\n",
    "### 关键FLAGS\n",
    "~~~python\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'train_path', os.path.dirname(os.path.abspath(__file__)) + '/train_logs',\n",
    "    'Directory where event logs are written to.')\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'checkpoint_path',\n",
    "    os.path.dirname(os.path.abspath(__file__)) + '/checkpoints',\n",
    "    'Directory where checkpoints are written to.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer('max_num_checkpoint', 10,\n",
    "                            'Maximum number of checkpoints that TensorFlow will keep.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer('num_classes', 2,\n",
    "                            'Number of model clones to deploy.')\n",
    "~~~\n",
    " **注意这部分要求参数为int，np.power需要转为int**\n",
    "~~~python\n",
    "tf.app.flags.DEFINE_integer('batch_size', int(np.power(2, 9)),\n",
    "                            'Number of model clones to deploy.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer('num_epochs', 10,\n",
    "                            'Number of epochs for training.')\n",
    "~~~\n",
    "### 学习速率、状态、错误警告\n",
    "~~~python\n",
    "#########################################\n",
    "########## learning rate #################\n",
    "#########################################\n",
    "tf.app.flags.DEFINE_float('initial_learning_rate', 0.001, 'Initial learning rate.')\n",
    "\n",
    "tf.app.flags.DEFINE_float(\n",
    "    'learning_rate_decay_factor', 0.95, 'Learning rate decay factor.')\n",
    "\n",
    "tf.app.flags.DEFINE_float(\n",
    "    'num_epochs_per_decay', 1, 'Number of epoch pass to decay learning rate.')\n",
    "\n",
    "#########################################\n",
    "########## status flags #################\n",
    "#########################################\n",
    "tf.app.flags.DEFINE_boolean('is_training', False,\n",
    "                            'Training/Testing.')\n",
    "\n",
    "tf.app.flags.DEFINE_boolean('fine_tuning', False,\n",
    "                            'Fine tuning is desired or not?.')\n",
    "\n",
    "tf.app.flags.DEFINE_boolean('online_test', True,\n",
    "                            'Fine tuning is desired or not?.')\n",
    "\n",
    "tf.app.flags.DEFINE_boolean('allow_soft_placement', True,\n",
    "                            'Automatically put the variables on CPU if there is no GPU support.')\n",
    "\n",
    "tf.app.flags.DEFINE_boolean('log_device_placement', False,\n",
    "                            'Demonstrate which variables are on what device.')\n",
    "\n",
    "# Store all elemnts in FLAG structure!\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "################################################\n",
    "################# handling errors!##############\n",
    "################################################\n",
    "if not os.path.isabs(FLAGS.train_path):\n",
    "    raise ValueError('You must assign absolute path for --train_path')\n",
    "\n",
    "if not os.path.isabs(FLAGS.checkpoint_path):\n",
    "    raise ValueError('You must assign absolute path for --checkpoint_path')\n",
    "~~~\n",
    "### 数据集处理\n",
    "**注意，需要提前下载MNIST数据集**\n",
    "http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz  \n",
    "http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz  \n",
    "http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz  \n",
    "http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz  \n",
    "数据集下载好之后存在项目文件目录下，进行引用  \n",
    "~~~python\n",
    "mnist = input_data.read_data_sets(\".\\MNIST_data/\", reshape=True, one_hot=False)\n",
    "~~~\n",
    "\n",
    "### 数据处理\n",
    "~~~python\n",
    "data = {}\n",
    "data['train/image'] = mnist.train.images\n",
    "data['train/label'] = mnist.train.labels\n",
    "data['test/image'] = mnist.test.images\n",
    "data['test/label'] = mnist.test.labels\n",
    "# 只获取训练集中标记有0和1的样本\n",
    "index_list_train = []\n",
    "for sample_index in range(data['train/label'].shape[0]):\n",
    "    # 拿到标签\n",
    "    label = data['train/label'][sample_index]\n",
    "    if label == 1 or label == 0:\n",
    "        index_list_train.append(sample_index)\n",
    "\n",
    "data['train/image'] = mnist.train.images[index_list_train]\n",
    "data['train/label'] = mnist.train.labels[index_list_train]\n",
    "# 同样，只获取测试集中标记有0和1的样本\n",
    "index_list_test = []\n",
    "for sample_index in range(data['test/label'].shape[0]):\n",
    "    # 拿到标签\n",
    "    label = data['test/label'][sample_index]\n",
    "    if label == 1 or label == 0:\n",
    "        index_list_test.append(sample_index)\n",
    "\n",
    "data['test/image'] = mnist.test.images[index_list_test]\n",
    "data['test/label'] = mnist.test.labels[index_list_test]\n",
    "~~~\n",
    "### 训练维度\n",
    "~~~python\n",
    "dimensionality_train = data['train/image'].shape\n",
    "num_train_samples = dimensionality_train[0]\n",
    "num_features = dimensionality_train[1]\n",
    "~~~\n",
    "### 设定图示（Tensorflow的图）\n",
    "graph = tf.Graph()\n",
    "### 逻辑回归实现\n",
    "逻辑回归的结构：是一个简单的通过完全连接的层来馈送转发输入特征，其中最后一层仅具有两个类。\n",
    "~~~python\n",
    "with graph.as_default():\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "    #步长策略\n",
    "    decay_steps = int(num_train_samples / FLAGS.batch_size *\n",
    "                      FLAGS.num_epochs_per_decay)\n",
    "    learning_rate = tf.train.exponential_decay(FLAGS.initial_learning_rate,\n",
    "                                               global_step,\n",
    "                                               decay_steps,\n",
    "                                               FLAGS.learning_rate_decay_factor,\n",
    "                                               staircase=True,\n",
    "                                               name='exponential_decay_learning_rate')\n",
    "\n",
    "\n",
    "    #设定占位符\n",
    "    image_place = tf.placeholder(tf.float32, shape=([None, num_features]), name='image')\n",
    "    label_place=tf.placeholder(tf.float32, shape=([None, ]), name='gt')\n",
    "    label_one_hot=tf.one_hot(label_place, depth=FLAGS.num_classes, axis=-1)\n",
    "    dropout_param=tf.placeholder(tf.float32)\n",
    "\n",
    "    #模型，损失函数，正确率\n",
    "    #一个简单的完全连接两个类和一个softmax相当于Logistic回归\n",
    "    logits = tf.contrib.layers.fully_connected(inputs=image_place, num_outputs=FLAGS.num_classes, scope='fc')\n",
    "    #损失\n",
    "    with tf.name_scope('loss'):\n",
    "        loss_tensor = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=label_one_hot))\n",
    "    #正确率\n",
    "    #评估模型\n",
    "    prediction_correct = tf.equal(tf.argmax(logits, 1), tf.argmax(label_one_hot, 1))\n",
    "    #正确率计算\n",
    "    accuracy = tf.reduce_mean(tf.cast(prediction_correct, tf.float32))\n",
    "\n",
    "    #训练操作\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    with tf.name_scope('train_op'):\n",
    "        gradients_and_variables = optimizer.compute_gradients(loss_tensor)\n",
    "        train_op = optimizer.apply_gradients(gradients_and_variables, global_step=global_step)\n",
    "\n",
    "    #运行会话操作\n",
    "    session_conf=tf.ConfigProto(\n",
    "        allow_soft_placement=FLAGS.allow_soft_palcement,\n",
    "        log_device_placement=FLAGS.log_device_placement\n",
    "    )\n",
    "    sess=tf.Session(graph=graph,config=session_conf)\n",
    "    with sess.as_default():\n",
    "        saver=tf.train.Saver()\n",
    "        #初始化所有变量\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        #已经完成拟合的文件\n",
    "        #TensorFlow的Saver类是通过操作checkpoint文件来实现对变量（Variable）的存储和恢复。checkpoint文件是二进制的文件，存放着按照固定格式存储的“变量名-Tensor值”map对\n",
    "        #checkpoint文件可以直接用记事本打开，里面存放的是最新模型的path和所有模型的path在\n",
    "        checkpoint_prefix='model'\n",
    "        #如果完成好的调谐，模型将被重新保存\n",
    "        if FLAGS.fin_tuning:\n",
    "            saver.restore(sess, os.path.join(FLAGS.checkpoint_path, checkpoint_prefix))\n",
    "            print(\"Model restored for fine-tuning...\")\n",
    "~~~\n",
    "# 注意\n",
    "[batch、batch size、epoch](https://blog.csdn.net/menc15/article/details/71628019)  \n",
    "- batch: batch是批。深度学习每一次参数的更新所需要损失函数并不是由一个{data：label}获得的，而是由一组数据加权得到的，这一组数据的数量就是batch size。batch的思想，至少有两个作用，一是更好的处理非凸的损失函数，非凸的情况下， 全样本就算工程上算的动， 也会卡在局部优上，批表示了全样本的部分抽样实现，相当于人为引入修正梯度上的采样噪声，使“一路不通找别路”更有可能搜索最优值；二是合理利用内存容量。\n",
    "- 如果数据集较小，可以采用全数据集（Full batch learning）的形式，这样有两个显然的好处：1.由全数据集计算的梯度能够更好的代表样本总体，从而更准确的朝向极值所在的方向；2.不同权重的梯度值差别很大，因此选取一个全局的学习率会比较困难（？）batch size最大是样本总数N，此时就是Full batch learning；最小是1，即每次只训练一个样本，这就是在线学习（Online Learning）。\n",
    "- 当我们分批学习时，每次使用过全部训练数据完成一次Forword运算以及一次BP运算，成为完成了一次epoch。  \n",
    "### 接下来的代码接上面，同属session会话中\n",
    "~~~python\n",
    "        #运行训练和循环\n",
    "        test_accuracy=0\n",
    "        for epoch in range(FLAGS.num_epochs):\n",
    "            total_batch_training=int(data['train/image'].shape[0]/FLAGS.batch_size)\n",
    "\n",
    "            for batch_num in range(total_batch_training):\n",
    "                start_idx=batch_num*FLAGS.batch_size\n",
    "                end_idx=(batch_num+1)*FLAGS.batch_size\n",
    "                #使用batch数据进行拟合\n",
    "                train_batch_data, train_batch_label = data['train/image'][start_idx:end_idx], data['train/label'][start_idx:end_idx]\n",
    "                #运行优化操作（反向传播），计算损失和正确率\n",
    "                batch_loss, _, training_step=sess.run(\n",
    "                    [loss_tensor,train_op,global_step],\n",
    "                    feed_dict={image_place:train_batch_data,label_place:train_batch_label,dropout_param:0.5}\n",
    "                )\n",
    "            print('Epoch'+str(epoch+1)+',Training loss='+'{:.5f}'.format(batch_loss))\n",
    "\n",
    "        #保存模型\n",
    "        if not os.path.exists(FLAGS.checkpoint_path):\n",
    "            os.makedirs(FLAGS.checkpoint_path)\n",
    "\n",
    "        save_path=saver.save(sess, os.path.join(FLAGS.checkpoint_path, checkpoint_prefix))\n",
    "        print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "        # The prefix for checkpoint files\n",
    "        checkpoint_prefix = 'model'\n",
    "\n",
    "        #更新权重\n",
    "        saver.restore(sess, os.path.join(FLAGS.checkpoint_path, checkpoint_prefix))\n",
    "        print(\"Model restored...\")\n",
    "\n",
    "        #评估模型\n",
    "        test_accuracy = 100 * sess.run(accuracy, feed_dict={\n",
    "            image_place: data['test/image'],\n",
    "            label_place: data['test/label'],\n",
    "            dropout_param: 1.})\n",
    "\n",
    "        print(\"Final Test Accuracy is %% %.2f\" % test_accuracy)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
